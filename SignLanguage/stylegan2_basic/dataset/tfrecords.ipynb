{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19935,"status":"ok","timestamp":1610289730906,"user":{"displayName":"이도연","photoUrl":"","userId":"01121628625520708341"},"user_tz":-540},"id":"eJX-U3hqd682","outputId":"7b16f276-046e-45e4-f668-606046bbd95c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2163,"status":"ok","timestamp":1610289733071,"user":{"displayName":"이도연","photoUrl":"","userId":"01121628625520708341"},"user_tz":-540},"id":"82RdlyXOeDZj"},"outputs":[],"source":["import sys\r\n","sys.path.append('/content/gdrive/MyDrive/stylegan2_tobigs/')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3444,"status":"ok","timestamp":1610289734353,"user":{"displayName":"이도연","photoUrl":"","userId":"01121628625520708341"},"user_tz":-540},"id":"vqIq_HHkdzhD"},"outputs":[],"source":["import os\r\n","import glob\r\n","import numpy as np\r\n","import tensorflow as tf\r\n","\r\n","from tqdm import tqdm\r\n","# from tf_utils import allow_memory_growth\r\n","\r\n","# TFRecords\r\n","# http://solarisailab.com/archives/2603\r\n","def _bytes_feature(value):\r\n","    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\r\n","    if isinstance(value, type(tf.constant(0))):\r\n","        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\r\n","    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n","\r\n","\r\n","def _int64_list_feature(values):\r\n","    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\r\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\r\n","\r\n","\r\n","def _float_list_feature(value):\r\n","    \"\"\"Returns a float_list from a float / double.\"\"\"\r\n","    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\r\n","\r\n","# serialize 직렬화? byte 형태로 변환 -\u003e TFRecords\r\n","def serialize_example(image_str, label):\r\n","    feature = {\r\n","        'label': _float_list_feature(label),\r\n","        'image': _bytes_feature(image_str),\r\n","    }\r\n","\r\n","    # Create a Features message using tf.train.Example.\r\n","    # tf.train.Example을 이용해서 Feature messeage를 생성합니다.\r\n","    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\r\n","    return example_proto.SerializeToString() # SerializeToString 함수를 이용해서 binary string으로 변환\r\n","\r\n","\r\n","def tf_serialize_example(image_str, label):\r\n","    tf_string = tf.py_function(\r\n","        serialize_example,\r\n","        (image_str, label),\r\n","        tf.string)\r\n","    return tf.reshape(tf_string, ())  # The result is a scalar\r\n","\r\n","\r\n","def parse_fn(image_fn, labels, res):\r\n","    # load image: [res, res, 3]\r\n","    image = tf.io.read_file(image_fn)\r\n","    # for decode_bmp, decode_gif, decode_jpeg, and decode_png\r\n","    # to convert the input bytes string into a Tensor of type dtype.\r\n","    image = tf.io.decode_image(image, channels=3, dtype=tf.uint8)\r\n","    image.set_shape([None, None, 3]) # 3차원 RGB\r\n","    image = tf.image.resize(image, size=[res, res]) # resize!\r\n","    image.set_shape([res, res, 3])\r\n","    image = tf.cast(image, dtype=tf.uint8)\r\n","    image_str = tf.image.encode_png(image)\r\n","\r\n","    # set labels\r\n","    return image_str, labels\r\n","\r\n","\r\n","def create_tfrecord_data(input_data, output_fn, res):\r\n","    image_fns = input_data['image_fns']\r\n","    labels = input_data['labels']\r\n","\r\n","    dataset = tf.data.Dataset.from_tensor_slices((image_fns, labels))\r\n","    dataset = dataset.map(lambda f, l: parse_fn(f, l, res), num_parallel_calls=8) # image_fn -\u003e image_str\r\n","    dataset = dataset.map(lambda s, l: tf_serialize_example(s, l), num_parallel_calls=8)\r\n","    # TFRecords 쓰기\r\n","    writer = tf.data.experimental.TFRecordWriter(output_fn)\r\n","    writer.write(dataset)\r\n","    return\r\n","\r\n","def raw_data_to_npy(txt_path, parse_first_line=False):\r\n","    with open(txt_path) as f:\r\n","        raw_data = f.readlines()\r\n","\r\n","    raw_data = sorted(raw_data, key=lambda x:x.split(', ')[0])\r\n","\r\n","    if parse_first_line:\r\n","        raw_data = [rd.split(', ') for rd in raw_data]\r\n","    else:\r\n","        raw_data = [rd.split(', ')[1:] for rd in raw_data]\r\n","    \r\n","    npy_data = np.array(raw_data).astype(np.float)\r\n","    return npy_data\r\n","\r\n","\r\n","\r\n","def main():\r\n","    # allow_memory_growth() # 메모리 증가를 허용\r\n","\r\n","    # prepare variables\r\n","    res = 512\r\n","    divide = 1000\r\n","    data_base_dir = '/content/gdrive/MyDrive/stylegan2_tobigs/data/REAL0610'\r\n","    dst_tfrecord_dir = os.path.join(data_base_dir, 'tfrecords')\r\n","    if not os.path.exists(dst_tfrecord_dir):\r\n","        os.makedirs(dst_tfrecord_dir)\r\n","\r\n","    # load image file names\r\n","    image_fns = glob.glob(os.path.join(data_base_dir, 'Resize_Image', '**/*.png')) # .png 파일 다\r\n","    image_fns = sorted(image_fns)\r\n","\r\n","    # load labels\r\n","    label_fn = os.path.join(data_base_dir, 'label.txt')\r\n","    label_fn = raw_data_to_npy(label_fn)\r\n","\r\n","    # start converting\r\n","    n_total = len(image_fns)\r\n","    print(n_total)\r\n","    interval_list = [(v * divide, (v + 1) * divide) for v in range(n_total // divide)]\r\n","    for fn_idx, (start_idx, end_idx) in enumerate(tqdm(interval_list)):\r\n","        output_fn = os.path.join(dst_tfrecord_dir, f'{fn_idx:04d}.tfrecord') # 1000개씩 0001.tfrecord, 0002.tfrecord 식\r\n","\r\n","        sliced_data = {\r\n","            'image_fns': image_fns[start_idx:end_idx],\r\n","            'labels': label_fn[start_idx:end_idx],\r\n","        }\r\n","        create_tfrecord_data(sliced_data, output_fn, res)\r\n","    print('DONE!!')\r\n","    return\r\n","\r\n","\r\n","# if __name__ == '__main__':\r\n","#     main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"DZyU3h49eXp-"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/11 [00:00\u003c?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["11661\n"]},{"name":"stderr","output_type":"stream","text":[" 36%|███▋      | 4/11 [29:27\u003c51:42, 443.21s/it]"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-4-263240bbee7e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-3-842490757b1f\u003e\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_fn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         }\n\u001b[0;32m--\u003e 122\u001b[0;31m         \u001b[0mcreate_tfrecord_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliced_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DONE!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-3-842490757b1f\u003e\u001b[0m in \u001b[0;36mcreate_tfrecord_data\u001b[0;34m(input_data, output_fn, res)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# TFRecords 쓰기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 73\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/writers.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    113\u001b[0m               dataset_ops.get_legacy_output_types(dataset)))\n\u001b[1;32m    114\u001b[0m     return gen_experimental_dataset_ops.dataset_to_tf_record(\n\u001b[0;32m--\u003e 115\u001b[0;31m         dataset._variant_tensor, self._filename, self._compression_type)  # pylint: disable=protected-access\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_experimental_dataset_ops.py\u001b[0m in \u001b[0;36mdataset_to_tf_record\u001b[0;34m(input_dataset, filename, compression_type, name)\u001b[0m\n\u001b[1;32m   1131\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   1132\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetToTFRecord\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1133\u001b[0;31m         compression_type)\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bpLI06EjJth"},"outputs":[],"source":["import os\r\n","import glob\r\n","import tensorflow as tf\r\n","import numpy as np\r\n","from matplotlib import pyplot as plt\r\n","\r\n","\r\n","def parse_tfrecord(raw_record, res):\r\n","    feature_description = {\r\n","        'label': tf.io.FixedLenFeature([259], tf.float32),\r\n","        'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\r\n","    }\r\n","\r\n","    # parse feature\r\n","    parsed = tf.io.parse_single_example(raw_record, feature_description)\r\n","\r\n","    # labels\r\n","    labels = tf.reshape(parsed['label'], shape=[259])\r\n","\r\n","    # image\r\n","    image = tf.io.decode_png(parsed['image'])\r\n","    image = tf.image.resize(image, size=[res, res])\r\n","    image = tf.transpose(image, perm=[2, 0, 1])\r\n","    image = tf.cast(image, dtype=tf.dtypes.float32)\r\n","    image = image / 127.5 - 1.0\r\n","    image.set_shape([3, res, res])\r\n","    return image, labels\r\n","\r\n","\r\n","def input_fn(filenames, res, batch_size, epochs):\r\n","    files = tf.data.Dataset.from_tensor_slices(filenames)\r\n","    dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x),\r\n","                               # cycle_length: number of files to read concurrently\r\n","                               # If you want to read from all your files(*.tfrecord) to create a batch,\r\n","                               # set this to the number of files\r\n","                               cycle_length=len(filenames),\r\n","                               # block_length: each time we read from a file, reads block_length elements from this file\r\n","                               block_length=1)\r\n","    dataset = dataset.map(lambda x: parse_tfrecord(x, res), num_parallel_calls=8)\r\n","    dataset = dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\r\n","    dataset = dataset.repeat(epochs)\r\n","    dataset = dataset.batch(batch_size)\r\n","    dataset = dataset.prefetch(buffer_size=None)\r\n","    return dataset\r\n","\r\n","\r\n","def get_dataset(tfrecord_dir, res, batch_size, is_train):\r\n","    # get dataset\r\n","    filenames = glob.glob(os.path.join(tfrecord_dir, '*.tfrecord'))\r\n","    print(filenames)\r\n","    filenames = sorted(filenames)\r\n","    train_filenames = filenames[:-1]\r\n","    val_filenames = filenames[-1:]\r\n","    filenames = train_filenames if is_train else val_filenames\r\n","\r\n","    # create dataset\r\n","    dataset = input_fn(filenames, res, batch_size=batch_size, epochs=None)\r\n","    return dataset\r\n","\r\n","\r\n","def get_label_depth():\r\n","    # define label spec\r\n","    label_depths = {\r\n","        'label_dim': 254,\r\n","        'person_dim': 5,\r\n","        # 'label_dim': 258,\r\n","        # 'person_dim': 4,\r\n","        # 'keypoint_dim': 254,\r\n","    }\r\n","    return label_depths\r\n","\r\n","\r\n","def main():\r\n","    import numpy as np\r\n","    from PIL import Image\r\n","\r\n","    # res = 256\r\n","    res = 512\r\n","    data_base_dir = '/content/gdrive/MyDrive/stylegan2_tobigs/data/REAL0610'\r\n","    folder_name = 'tfrecords'\r\n","    tfrecord_dir = os.path.join(data_base_dir, folder_name)\r\n","    print(tfrecord_dir)\r\n","\r\n","    batch_size = 2\r\n","    is_train = True\r\n","\r\n","    # label_depths = get_label_depth()\r\n","    dataset = get_dataset(tfrecord_dir, res, batch_size, is_train)\r\n","\r\n","    for ii in range(3): # 이미지, 라벨 3개만 출력\r\n","        for real_images, labels in dataset.take(1):\r\n","            image_raw = real_images.numpy()\r\n","            image_raw = image_raw[0]\r\n","            image_raw = np.transpose(image_raw, axes=[1, 2, 0])\r\n","            image_raw = (image_raw + 1.0) * 127.5  # -1~1 -\u003e 0~255\r\n","            image = Image.fromarray(np.uint8(image_raw))\r\n","            image.show()\r\n","            plt.figure(figsize=(40,40))\r\n","            plt.subplot(1,3,ii+1)\r\n","            plt.imshow(image)\r\n","            plt.scatter(list(np.array(labels[0][:-5:2])*512), list(np.array(labels[0][1:-5:2])*512), s=0.2)\r\n","            # print(labels[0])\r\n","            print(len(labels[0]))\r\n","    return\r\n","\r\n","\r\n","# if __name__ == '__main__':\r\n","#     main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1zduQt4htzIzoByRHRRGpIQfPOWkONYFm"},"executionInfo":{"elapsed":24252,"status":"ok","timestamp":1610026918588,"user":{"displayName":"이도연","photoUrl":"","userId":"01121628625520708341"},"user_tz":-540},"id":"RMQvEQH_K3DG","outputId":"c8876ae0-f21e-4e1b-9c42-cd4314e37db6"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-LDBGEXLHfS"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMWJ21gsipf+j8n6WhKtSoS","collapsed_sections":[],"name":"tfrecords.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}