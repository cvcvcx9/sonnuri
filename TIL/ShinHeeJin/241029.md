# 241029
## 요약: 수어 코드 분석

## 텍스트(또는 수어 글로스)를 입력하면 3D 골격 좌표로 변환하여 수어 동작을 생성하는 시스템

1. **주요 파일들**:

```
plaintext
Copy
text2keypoint/
├── __main__.py        # 실행 파일
├── Base.yaml          # 설정 파일
├── data/
│   └── data.py        # 데이터 로딩 & 전처리
└── modeling/
    ├── model.py       # 신경망 모델 구조
    ├── tacotron.py    # 텍스트->동작 변환 모델
    ├── key2video.py   # 좌표->이미지/비디오 
    └── prediction.py  # 예측 결과 생성

```

1. **데이터 흐름**:

```
[입력 데이터]
  ↓
텍스트/글로스 → 3D 좌표 → 스틱 피겨 이미지 → 비디오
"안녕하세요"  →  (x,y,z) →    🕴️    →   🎥
```

1. **각 파일별 상세 설명**:

a) **Base.yaml** (설정 파일):

```yaml
mode: "Train"# 학습 or 테스트 모드 선택
data_path: "./data/sample_data/"# 데이터 위치
```

- 수정 포인트: 데이터 경로, 학습/테스트 모드 설정

b) **data.py** (데이터 처리):

```python
# 입력 데이터 형식:
train.files# 파일명 목록
train.gloss# 수어 문장
train.skels# 3D 좌표 데이터# 주요 기능:
- 텍스트 데이터 토큰화
- 좌표 데이터 정규화
- 학습용 데이터 생성
```

- 수정 포인트: 데이터 형식에 맞게 입력 파일 준비

c) **model.py** & **tacotron.py** (모델):

```python
# Tacotron 기반 모델:
1. 텍스트 인코딩
2. 어텐션 메커니즘
3. 디코더
4. 3D 좌표 생성
```

- 수정 포인트: 모델 파라미터, 구조 수정

d) **key2video.py** (시각화):

```python
def create_stick(filename, keypoints, save_path):
# 3D 좌표 → 스틱 피겨 이미지# 신체 부위별 연결점 정의# 이미지 생성

def create_video(save_path):
# 이미지들을 연결하여 비디오 생성
```

- 수정 포인트: 이미지 크기, FPS, 비디오 형식
1. **실행 과정**:

```bash
# 1. 데이터 준비
data/sample_data/ 폴더에
- train.files
- train.gloss
- train.skels
파일들을 위치

# 2. 설정
Base.yaml 파일에서
mode: "Train" 설정

# 3. 실행
python __main__.py
```

1. **생성되는 결과물**:

```
plaintext
Copy
Models/
└── result/
    ├── json/          # 예측된 3D 좌표
    └── img_video/     # 생성된 이미지와 비디오
        └── real/      # 실제 데이터의 시각화

```

1. **사용 예시**:

```python
python
Copy
# 예: "안녕하세요"를 수어로 변환
입력: "안녕하세요"
↓
중간 결과: [x1,y1,z1, x2,y2,z2, ...] (3D 좌표)
↓
최종 결과:
- 스틱 피겨 이미지 시퀀스
- 수어 동작 비디오

```

1. **주요 수정 포인트**:
2. 데이터 준비:
    - 수어 문장 (.gloss)
    - 해당하는 3D 좌표 (.skels)
3. 설정 변경:
    - 학습/테스트 모드
    - 데이터 경로
    - 모델 파라미터
4. 결과 형식:
    - 이미지 크기
    - 비디오 FPS
    - 저장 형식